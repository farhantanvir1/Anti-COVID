{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "costco_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhantanvir1/Anti-COVID/blob/main/costco_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJRhgXMRZJMa"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZej76fZPqZ"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras as k"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "2Z6vT1d74VeQ",
        "outputId": "64c7410e-830d-47d8-9897-13df7f2c801d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHGhMhifVRNo"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kueTfyY3Yht2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "73827a4d-d357-497d-f3a5-e6227ada46e9"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "data_folder = 'data'\n",
        "\n",
        "if not os.path.exists(data_folder):\n",
        "  url = 'https://github.com/USC-Melady/KDD19-CoSTCo/releases/download/demo_data/data.zip'\n",
        "  filedata = urllib2.urlopen(url)\n",
        "\n",
        "  with open('data.zip', 'wb') as f:\n",
        "      f.write(filedata.read())\n",
        "\n",
        "  with zipfile.ZipFile('data.zip', 'r') as f:\n",
        "    f.extractall('.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'urllib2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-37df18ab4467>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://github.com/USC-Melady/KDD19-CoSTCo/releases/download/demo_data/data.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mfiledata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'urllib2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ilig1cCVRNp"
      },
      "source": [
        "shape = np.loadtxt(os.path.join(data_folder, 'tensor_shape.txt')).astype(int)\n",
        "tr_idxs = np.loadtxt(os.path.join(data_folder, 'train_indices.txt')).astype(int)\n",
        "tr_vals = np.loadtxt(os.path.join(data_folder, 'train_values.txt'))\n",
        "te_idxs = np.loadtxt(os.path.join(data_folder, 'test_indices.txt')).astype(int)\n",
        "te_vals = np.loadtxt(os.path.join(data_folder, 'test_values.txt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB4BuZRbVRNY"
      },
      "source": [
        "# Define util functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MmoK-zQVRNZ"
      },
      "source": [
        "def mape_keras(y_true, y_pred, threshold=0.1):\n",
        "    v = k.backend.clip(k.backend.abs(y_true), threshold, None)\n",
        "    diff = k.backend.abs((y_true - y_pred) / v)\n",
        "    return 100.0 * k.backend.mean(diff, axis=-1)\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    return np.mean(np.abs(y_pred - y_true))\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
        "\n",
        "def mape(y_true, y_pred, threshold=0.1):\n",
        "    v = np.clip(np.abs(y_true), threshold, None)\n",
        "    diff = np.abs((y_true - y_pred) / v)\n",
        "    return 100.0 * np.mean(diff, axis=-1).mean()\n",
        "\n",
        "def transform(idxs):\n",
        "    return [idxs[:, i] for i in range(idxs.shape[1])]\n",
        "\n",
        "def set_session(device_count=None, seed=0):\n",
        "    gpu_options = tf.GPUOptions(allow_growth=True)\n",
        "    if device_count is not None:\n",
        "        config = tf.ConfigProto(\n",
        "            gpu_options=gpu_options,\n",
        "            device_count=device_count\n",
        "        )\n",
        "    else:\n",
        "        config = tf.ConfigProto(gpu_options=gpu_options)\n",
        "    sess = tf.Session(config=config)\n",
        "    k.backend.set_session(sess)\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    tf.set_random_seed(seed)\n",
        "    return sess\n",
        "\n",
        "def get_metrics(model, x, y, batch_size=1024):\n",
        "    yp = model.predict(x, batch_size=batch_size, verbose=1).flatten()\n",
        "    return {\n",
        "        \"rmse\": float(rmse(y, yp)),\n",
        "        \"mape\": float(mape(y, yp)),\n",
        "        \"mae\": float(mae(y, yp))\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xim4s-ziVRNg"
      },
      "source": [
        "# Create a CoSTCo model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci6JG9m9VRNh"
      },
      "source": [
        "def create_costco(shape, rank, nc):\n",
        "    inputs = [k.Input(shape=(1,), dtype=\"int32\") for i in range(len(shape))]\n",
        "    embeds = [\n",
        "        k.layers.Embedding(output_dim=rank, input_dim=shape[i])(inputs[i])\n",
        "        for i in range(len(shape))\n",
        "    ]\n",
        "    x = k.layers.Concatenate(axis=1)(embeds)\n",
        "    x = k.layers.Reshape(target_shape=(rank, len(shape), 1))(x)\n",
        "    x = k.layers.Conv2D(\n",
        "        nc,\n",
        "        kernel_size=(1, len(shape)),\n",
        "        activation=\"relu\",\n",
        "        padding=\"valid\"\n",
        "    )(x)\n",
        "    x = k.layers.Conv2D(\n",
        "        nc,\n",
        "        kernel_size=(rank, 1),\n",
        "        activation=\"relu\",\n",
        "        padding=\"valid\"\n",
        "    )(x)\n",
        "    x = k.layers.Flatten()(x)\n",
        "    x = k.layers.Dense(nc, activation=\"relu\")(x)\n",
        "    outputs = k.layers.Dense(1, activation=\"relu\")(x)\n",
        "    model = k.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ_cVComVRNk"
      },
      "source": [
        "# Set hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsdsNRmEVRNl"
      },
      "source": [
        "lr = 1e-4\n",
        "rank = 20\n",
        "nc = rank\n",
        "epochs = 50\n",
        "batch_size = 256\n",
        "\n",
        "seed = 3\n",
        "verbose = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lQi9W2OVRNr"
      },
      "source": [
        "# Train with early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzRKa3PvVRNs"
      },
      "source": [
        "set_session(device_count={\"GPU\": 0}, seed=seed)\n",
        "optim = k.optimizers.Adam(lr=lr)\n",
        "\n",
        "model = create_costco(shape, rank, nc)\n",
        "model.compile(optim, loss=[\"mse\"], metrics=[\"mae\", mape_keras])\n",
        "hists = model.fit(\n",
        "    x=transform(tr_idxs),\n",
        "    y=tr_vals,\n",
        "    verbose=verbose,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[k.callbacks.EarlyStopping(\n",
        "        monitor=\"val_mean_absolute_error\",\n",
        "        patience=10,\n",
        "        restore_best_weights=True)],\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1bLRaV1VRNx"
      },
      "source": [
        "# Evaluation model prediction over the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zi71CQmVRNx"
      },
      "source": [
        "tr_info = get_metrics(model, transform(tr_idxs), tr_vals)\n",
        "te_info = get_metrics(model, transform(te_idxs), te_vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RT8lnIlXtsx"
      },
      "source": [
        "pprint({'train': tr_info, 'test': te_info})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as k\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
        "\n",
        "# Load DMD dataset\n",
        "data_file = \"/content/adj_del_4mic_myid.txt\"\n",
        "\n",
        "# Load triplet associations (drug, microbe, disease, label)\n",
        "data = np.loadtxt(data_file).astype(int)\n",
        "\n",
        "# Extract triplet indices and labels\n",
        "d_indices = data[:, 0]  # Drug indices\n",
        "m_indices = data[:, 1]  # Microbe indices\n",
        "n_indices = data[:, 2]  # Disease indices\n",
        "labels = data[:, 3].astype(float)  # Convert to float for label smoothing\n",
        "\n",
        "# Get dataset shape (number of unique drugs, microbes, diseases)\n",
        "num_drugs = np.max(d_indices) + 1\n",
        "num_microbes = np.max(m_indices) + 1\n",
        "num_diseases = np.max(n_indices) + 1\n",
        "shape = [num_drugs, num_microbes, num_diseases]\n",
        "\n",
        "# Convert dataset into a set for fast lookup\n",
        "positive_set = set(tuple(row[:3]) for row in data)\n",
        "\n",
        "# Generate negative samples\n",
        "num_neg_samples = len(data)  # 1:1 ratio of negative to positive\n",
        "negative_samples = []\n",
        "while len(negative_samples) < num_neg_samples:\n",
        "    d_neg = np.random.randint(0, num_drugs)\n",
        "    m_neg = np.random.randint(0, num_microbes)\n",
        "    n_neg = np.random.randint(0, num_diseases)\n",
        "\n",
        "    if (d_neg, m_neg, n_neg) not in positive_set:  # Ensure it's a negative sample\n",
        "        negative_samples.append([d_neg, m_neg, n_neg, 0])  # Label 0\n",
        "\n",
        "# Merge positive and negative samples\n",
        "negative_samples = np.array(negative_samples)\n",
        "data = np.vstack((data, negative_samples))\n",
        "\n",
        "# Shuffle dataset to avoid ordering bias\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(data)\n",
        "\n",
        "# Define train-test split (80% train, 20% test)\n",
        "split_idx = int(0.8 * len(data))\n",
        "train_indices, test_indices = data[:split_idx, :3], data[split_idx:, :3]\n",
        "train_labels, test_labels = data[:split_idx, 3], data[split_idx:, 3]\n",
        "\n",
        "# Function to transform input indices for the model\n",
        "def transform(idxs):\n",
        "    return [idxs[:, i] for i in range(idxs.shape[1])]\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_session(seed=0):\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        except RuntimeError as e:\n",
        "            print(e)\n",
        "\n",
        "# Define CoSTCo Model with Dropout, L2 Regularization, and Noise Injection\n",
        "def create_costco(shape, rank, nc):\n",
        "    inputs = [k.Input(shape=(1,), dtype=\"int32\") for i in range(len(shape))]\n",
        "    embeds = [\n",
        "        k.layers.Embedding(output_dim=rank, input_dim=shape[i])(inputs[i])\n",
        "        for i in range(len(shape))\n",
        "    ]\n",
        "    x = k.layers.Concatenate(axis=1)(embeds)\n",
        "    x = k.layers.Reshape(target_shape=(rank, len(shape), 1))(x)\n",
        "\n",
        "    x = k.layers.Conv2D(\n",
        "        nc // 2,\n",
        "        kernel_size=(1, len(shape)),\n",
        "        activation=\"relu\",\n",
        "        padding=\"valid\"\n",
        "    )(x)\n",
        "    x = k.layers.Conv2D(\n",
        "        nc // 2,\n",
        "        kernel_size=(rank, 1),\n",
        "        activation=\"relu\",\n",
        "        padding=\"valid\"\n",
        "    )(x)\n",
        "\n",
        "    x = k.layers.Flatten()(x)\n",
        "    x = k.layers.Dense(nc, activation=\"relu\", kernel_regularizer=k.regularizers.l2(0.05))(x)\n",
        "    x = k.layers.GaussianNoise(0.1)(x)\n",
        "    x = k.layers.Dropout(0.5)(x)\n",
        "    outputs = k.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = k.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Training parameters\n",
        "lr = 1e-4\n",
        "rank = 10\n",
        "nc = rank\n",
        "epochs = 20\n",
        "batch_size = 256\n",
        "seed = 42\n",
        "verbose = 1\n",
        "\n",
        "# Set session\n",
        "set_session(seed=seed)\n",
        "\n",
        "# Model initialization and training\n",
        "optim = k.optimizers.Adam(learning_rate=lr)\n",
        "model = create_costco(shape, rank, nc)\n",
        "model.compile(optimizer=optim, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "hists = model.fit(\n",
        "    x=transform(train_indices),\n",
        "    y=train_labels,\n",
        "    verbose=verbose,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[k.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        mode='min')]\n",
        ")\n",
        "\n",
        "# Evaluate model\n",
        "test_preds = model.predict(transform(test_indices), batch_size=batch_size).flatten()\n",
        "\n",
        "# Convert predictions to binary format for classification metrics\n",
        "test_preds_binary = (test_preds >= 0.5).astype(int)\n",
        "\n",
        "# Compute Classification Metrics\n",
        "def calculate_classification_metrics(y_true, y_pred, threshold=0.5):\n",
        "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
        "    metrics = {\n",
        "        \"F1-score\": f1_score(y_true, y_pred_binary),\n",
        "        \"Precision\": precision_score(y_true, y_pred_binary),\n",
        "        \"Recall\": recall_score(y_true, y_pred_binary),\n",
        "        \"ROC-AUC\": roc_auc_score(y_true, y_pred) if len(np.unique(y_true)) > 1 else 0.0,\n",
        "        \"Average Precision\": average_precision_score(y_true, y_pred)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "classification_metrics = calculate_classification_metrics(test_labels, test_preds)\n",
        "\n",
        "# Compute Ranking Metrics\n",
        "def hit_at_n(y_true, y_pred, N=5):\n",
        "    sorted_indices = np.argsort(-y_pred)\n",
        "    top_n = sorted_indices[:N]\n",
        "    return 1 if any(y_true[i] for i in top_n) else 0\n",
        "\n",
        "def ndcg_at_n(y_true, y_pred, N=5):\n",
        "    sorted_indices = np.argsort(-y_pred)\n",
        "    ideal_sorted_indices = np.argsort(-y_true)\n",
        "    dcg = sum((y_true[i] / np.log2(idx + 2)) for idx, i in enumerate(sorted_indices[:N]))\n",
        "    idcg = sum((y_true[i] / np.log2(idx + 2)) for idx, i in enumerate(ideal_sorted_indices[:N]))\n",
        "    return dcg / idcg if idcg > 0 else 0\n",
        "\n",
        "# Print Evaluation Metrics\n",
        "for i in range(1,6,2):\n",
        "    hit_n = hit_at_n(test_labels, test_preds, N=i)\n",
        "    ndcg_n = ndcg_at_n(test_labels, test_preds, N=i)\n",
        "    print(f\"Hit@{i}: {hit_n:.4f}\")\n",
        "    print(f\"NDCG@{i}: {ndcg_n:.4f}\")\n",
        "\n",
        "print(\"Classification Metrics:\")\n",
        "for metric, value in classification_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ],
      "metadata": {
        "id": "VxiJEwI-7aAj",
        "outputId": "15ffb39d-0cb0-47dc-dead-e5800e8fbeb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 347ms/step - accuracy: 0.5336 - loss: 1.0194 - val_accuracy: 0.5317 - val_loss: 1.0164\n",
            "Epoch 2/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4980 - loss: 1.0219 - val_accuracy: 0.5814 - val_loss: 1.0136\n",
            "Epoch 3/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5088 - loss: 1.0202 - val_accuracy: 0.6086 - val_loss: 1.0108\n",
            "Epoch 4/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5148 - loss: 1.0147 - val_accuracy: 0.6425 - val_loss: 1.0078\n",
            "Epoch 5/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4932 - loss: 1.0128 - val_accuracy: 0.6719 - val_loss: 1.0046\n",
            "Epoch 6/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5210 - loss: 1.0078 - val_accuracy: 0.7014 - val_loss: 1.0014\n",
            "Epoch 7/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4971 - loss: 1.0072 - val_accuracy: 0.7081 - val_loss: 0.9982\n",
            "Epoch 8/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5339 - loss: 0.9987 - val_accuracy: 0.7421 - val_loss: 0.9949\n",
            "Epoch 9/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5229 - loss: 0.9989 - val_accuracy: 0.7602 - val_loss: 0.9915\n",
            "Epoch 10/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5218 - loss: 0.9930 - val_accuracy: 0.7919 - val_loss: 0.9881\n",
            "Epoch 11/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5211 - loss: 0.9951 - val_accuracy: 0.8054 - val_loss: 0.9847\n",
            "Epoch 12/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5363 - loss: 0.9871 - val_accuracy: 0.8258 - val_loss: 0.9811\n",
            "Epoch 13/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5389 - loss: 0.9835 - val_accuracy: 0.8462 - val_loss: 0.9773\n",
            "Epoch 14/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5434 - loss: 0.9816 - val_accuracy: 0.8529 - val_loss: 0.9734\n",
            "Epoch 15/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5454 - loss: 0.9793 - val_accuracy: 0.8462 - val_loss: 0.9695\n",
            "Epoch 16/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 0.9734 - val_accuracy: 0.8462 - val_loss: 0.9656\n",
            "Epoch 17/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5647 - loss: 0.9683 - val_accuracy: 0.8439 - val_loss: 0.9616\n",
            "Epoch 18/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5661 - loss: 0.9648 - val_accuracy: 0.8507 - val_loss: 0.9573\n",
            "Epoch 19/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5548 - loss: 0.9640 - val_accuracy: 0.8552 - val_loss: 0.9528\n",
            "Epoch 20/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5778 - loss: 0.9565 - val_accuracy: 0.8575 - val_loss: 0.9482\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step\n",
            "Hit@1: 1.0000\n",
            "NDCG@1: 1.0000\n",
            "Hit@3: 1.0000\n",
            "NDCG@3: 1.0000\n",
            "Hit@5: 1.0000\n",
            "NDCG@5: 1.0000\n",
            "Classification Metrics:\n",
            "F1-score: 0.8277\n",
            "Precision: 0.8636\n",
            "Recall: 0.7947\n",
            "ROC-AUC: 0.9061\n",
            "Average Precision: 0.9094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NeurTN Code"
      ],
      "metadata": {
        "id": "4nTZIXBrca5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "id": "i-bqgmEYeqNn",
        "outputId": "11e78390-9b94-446c-b943-e23d8b972273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset (Update path if necessary)\n",
        "data_file = \"/content/adj_del_4mic_myid.txt\"\n",
        "data = np.loadtxt(data_file).astype(int)\n",
        "\n",
        "# Extract triplet indices and labels\n",
        "d_indices = data[:, 0]  # Drug indices\n",
        "m_indices = data[:, 1]  # Microbe indices\n",
        "n_indices = data[:, 2]  # Disease indices\n",
        "labels = data[:, 3]     # Association labels (0 or 1)\n",
        "\n",
        "# Get dataset shape (number of unique drugs, microbes, diseases)\n",
        "num_drugs = np.max(d_indices) + 1\n",
        "num_microbes = np.max(m_indices) + 1\n",
        "num_diseases = np.max(n_indices) + 1\n",
        "\n",
        "# Convert to tensor format\n",
        "triplets = torch.tensor(np.column_stack((d_indices, m_indices, n_indices)), dtype=torch.long)\n",
        "labels = torch.tensor(labels, dtype=torch.float)\n",
        "\n",
        "def generate_negative_samples(triplets, labels, num_samples):\n",
        "    \"\"\"\n",
        "    Generate negative samples by randomly replacing microbes or diseases.\n",
        "    \"\"\"\n",
        "    negative_triplets = triplets.clone().detach()\n",
        "    for i in range(num_samples):\n",
        "        idx = torch.randint(0, len(triplets), (1,))\n",
        "        if torch.rand(1).item() < 0.5:\n",
        "            negative_triplets[idx, 1] = torch.randint(0, num_microbes, (1,))  # Random microbe\n",
        "        else:\n",
        "            negative_triplets[idx, 2] = torch.randint(0, num_diseases, (1,))  # Random disease\n",
        "\n",
        "    negative_labels = torch.zeros(num_samples, dtype=torch.float)\n",
        "    return negative_triplets, negative_labels\n",
        "\n",
        "# Generate an equal number of negative samples\n",
        "neg_triplets, neg_labels = generate_negative_samples(triplets, labels, len(triplets))\n",
        "\n",
        "# Combine positive and negative samples\n",
        "triplets = torch.cat((triplets, neg_triplets), dim=0)\n",
        "labels = torch.cat((labels, neg_labels), dim=0)\n",
        "\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_triplets, test_triplets, train_labels, test_labels = train_test_split(triplets, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Move data to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_triplets, train_labels = train_triplets.to(device), train_labels.to(device)\n",
        "test_triplets, test_labels = test_triplets.to(device), test_labels.to(device)\n",
        "\n",
        "\n",
        "class NeurTN(nn.Module):\n",
        "    def __init__(self, num_drugs, num_microbes, num_diseases, embed_dim=256, gnn_dim=128, mlp_dim=256):\n",
        "        super(NeurTN, self).__init__()\n",
        "\n",
        "        # Embedding layers\n",
        "        self.drug_embedding = nn.Embedding(num_drugs, embed_dim)\n",
        "        self.microbe_embedding = nn.Embedding(num_microbes, embed_dim)\n",
        "        self.disease_embedding = nn.Embedding(num_diseases, embed_dim)\n",
        "\n",
        "        # GNN for drug molecules\n",
        "        self.gnn_conv1 = GCNConv(embed_dim, gnn_dim)\n",
        "        self.gnn_conv2 = GCNConv(gnn_dim, gnn_dim)\n",
        "\n",
        "        # MLP component\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 3, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(mlp_dim),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(mlp_dim, mlp_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(mlp_dim // 2),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(mlp_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, drug_idx, microbe_idx, disease_idx):\n",
        "        # Embedding lookup\n",
        "        drug_emb = self.drug_embedding(drug_idx)\n",
        "        microbe_emb = self.microbe_embedding(microbe_idx)\n",
        "        disease_emb = self.disease_embedding(disease_idx)\n",
        "\n",
        "        # Feature fusion\n",
        "        combined_emb = torch.cat([drug_emb, microbe_emb, disease_emb], dim=1)\n",
        "        mlp_output = self.mlp(combined_emb)\n",
        "\n",
        "        return torch.sigmoid(mlp_output)  # Sigmoid activation for binary classification\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "model = NeurTN(num_drugs, num_microbes, num_diseases).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Sample a mini-batch\n",
        "    indices = torch.randperm(len(train_triplets))[:batch_size]\n",
        "    batch_triplets = train_triplets[indices]\n",
        "    batch_labels = train_labels[indices]\n",
        "\n",
        "    predictions = model(batch_triplets[:, 0], batch_triplets[:, 1], batch_triplets[:, 2]).squeeze()\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_preds = model(test_triplets[:, 0], test_triplets[:, 1], test_triplets[:, 2]).cpu().numpy().flatten()\n",
        "    test_preds_binary = (test_preds >= 0.5).astype(int)\n",
        "\n",
        "# Compute Classification Metrics\n",
        "def calculate_classification_metrics(y_true, y_pred):\n",
        "    y_pred_binary = (y_pred >= 0.5).astype(int)\n",
        "    metrics = {\n",
        "        \"F1-score\": f1_score(y_true, y_pred_binary),\n",
        "        \"Precision\": precision_score(y_true, y_pred_binary),\n",
        "        \"Recall\": recall_score(y_true, y_pred_binary),\n",
        "        \"ROC-AUC\": roc_auc_score(y_true, y_pred),\n",
        "        \"Average Precision\": average_precision_score(y_true, y_pred)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "classification_metrics = calculate_classification_metrics(test_labels.cpu().numpy(), test_preds)\n",
        "\n",
        "# Print Evaluation Metrics\n",
        "print(\"\\nClassification Metrics:\")\n",
        "for metric, value in classification_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n"
      ],
      "metadata": {
        "id": "KgPBh4VEcaE4",
        "outputId": "68a16887-b0d6-4053-a119-e337eb6fb58a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7281\n",
            "Epoch 2, Loss: 0.7014\n",
            "Epoch 3, Loss: 0.6931\n",
            "Epoch 4, Loss: 0.6299\n",
            "Epoch 5, Loss: 0.6290\n",
            "Epoch 6, Loss: 0.6693\n",
            "Epoch 7, Loss: 0.6267\n",
            "Epoch 8, Loss: 0.6504\n",
            "Epoch 9, Loss: 0.6054\n",
            "Epoch 10, Loss: 0.6103\n",
            "Epoch 11, Loss: 0.6355\n",
            "Epoch 12, Loss: 0.6219\n",
            "Epoch 13, Loss: 0.6339\n",
            "Epoch 14, Loss: 0.5906\n",
            "Epoch 15, Loss: 0.5805\n",
            "Epoch 16, Loss: 0.5984\n",
            "Epoch 17, Loss: 0.6241\n",
            "Epoch 18, Loss: 0.5465\n",
            "Epoch 19, Loss: 0.5707\n",
            "Epoch 20, Loss: 0.6405\n",
            "Epoch 21, Loss: 0.5638\n",
            "Epoch 22, Loss: 0.5815\n",
            "Epoch 23, Loss: 0.5694\n",
            "Epoch 24, Loss: 0.6038\n",
            "Epoch 25, Loss: 0.5869\n",
            "Epoch 26, Loss: 0.5635\n",
            "Epoch 27, Loss: 0.6010\n",
            "Epoch 28, Loss: 0.5590\n",
            "Epoch 29, Loss: 0.5644\n",
            "Epoch 30, Loss: 0.5719\n",
            "Epoch 31, Loss: 0.5259\n",
            "Epoch 32, Loss: 0.5620\n",
            "Epoch 33, Loss: 0.5641\n",
            "Epoch 34, Loss: 0.5450\n",
            "Epoch 35, Loss: 0.5357\n",
            "Epoch 36, Loss: 0.5504\n",
            "Epoch 37, Loss: 0.5150\n",
            "Epoch 38, Loss: 0.5066\n",
            "Epoch 39, Loss: 0.5671\n",
            "Epoch 40, Loss: 0.5276\n",
            "Epoch 41, Loss: 0.5312\n",
            "Epoch 42, Loss: 0.5192\n",
            "Epoch 43, Loss: 0.4820\n",
            "Epoch 44, Loss: 0.4939\n",
            "Epoch 45, Loss: 0.4675\n",
            "Epoch 46, Loss: 0.5140\n",
            "Epoch 47, Loss: 0.5351\n",
            "Epoch 48, Loss: 0.4894\n",
            "Epoch 49, Loss: 0.5026\n",
            "Epoch 50, Loss: 0.5367\n",
            "Epoch 51, Loss: 0.5289\n",
            "Epoch 52, Loss: 0.5010\n",
            "Epoch 53, Loss: 0.4520\n",
            "Epoch 54, Loss: 0.5036\n",
            "Epoch 55, Loss: 0.4741\n",
            "Epoch 56, Loss: 0.5458\n",
            "Epoch 57, Loss: 0.5373\n",
            "Epoch 58, Loss: 0.5145\n",
            "Epoch 59, Loss: 0.4995\n",
            "Epoch 60, Loss: 0.5635\n",
            "Epoch 61, Loss: 0.4487\n",
            "Epoch 62, Loss: 0.5060\n",
            "Epoch 63, Loss: 0.4857\n",
            "Epoch 64, Loss: 0.5253\n",
            "Epoch 65, Loss: 0.5390\n",
            "Epoch 66, Loss: 0.4679\n",
            "Epoch 67, Loss: 0.5017\n",
            "Epoch 68, Loss: 0.4985\n",
            "Epoch 69, Loss: 0.4747\n",
            "Epoch 70, Loss: 0.5232\n",
            "Epoch 71, Loss: 0.5311\n",
            "Epoch 72, Loss: 0.5140\n",
            "Epoch 73, Loss: 0.5362\n",
            "Epoch 74, Loss: 0.4637\n",
            "Epoch 75, Loss: 0.4533\n",
            "Epoch 76, Loss: 0.4325\n",
            "Epoch 77, Loss: 0.4911\n",
            "Epoch 78, Loss: 0.4472\n",
            "Epoch 79, Loss: 0.4978\n",
            "Epoch 80, Loss: 0.4839\n",
            "Epoch 81, Loss: 0.4597\n",
            "Epoch 82, Loss: 0.4556\n",
            "Epoch 83, Loss: 0.4731\n",
            "Epoch 84, Loss: 0.4396\n",
            "Epoch 85, Loss: 0.4696\n",
            "Epoch 86, Loss: 0.4934\n",
            "Epoch 87, Loss: 0.4174\n",
            "Epoch 88, Loss: 0.4564\n",
            "Epoch 89, Loss: 0.5130\n",
            "Epoch 90, Loss: 0.4442\n",
            "Epoch 91, Loss: 0.5201\n",
            "Epoch 92, Loss: 0.4894\n",
            "Epoch 93, Loss: 0.4619\n",
            "Epoch 94, Loss: 0.4843\n",
            "Epoch 95, Loss: 0.4672\n",
            "Epoch 96, Loss: 0.4742\n",
            "Epoch 97, Loss: 0.3826\n",
            "Epoch 98, Loss: 0.4797\n",
            "Epoch 99, Loss: 0.4761\n",
            "Epoch 100, Loss: 0.4749\n",
            "\n",
            "Classification Metrics:\n",
            "F1-score: 0.7020\n",
            "Precision: 0.6532\n",
            "Recall: 0.7587\n",
            "ROC-AUC: 0.6728\n",
            "Average Precision: 0.5971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PEG0KDkpzaak",
        "outputId": "0af4f03a-32f4-4c08-fbd5-ced4cb004335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "id": "1DoutMJTziBt",
        "outputId": "808a4f6b-8da7-4ff2-da46-626a9c53dc27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-scatter"
      ],
      "metadata": {
        "id": "cIP5j6npzrvO",
        "outputId": "9415d4f8-a63d-4847-c038-3bb379cd3dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=3622732 sha256=675de607588c6cf78ed82b2f51ec137246d1e906fe70f36f55812596b9d44156\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xlrd"
      ],
      "metadata": {
        "id": "AUiO4i4KXACg",
        "outputId": "6402a467-f0b5-4416-a43f-7c94ba2659de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rdkit"
      ],
      "metadata": {
        "id": "EwEKy8C7v68V",
        "outputId": "67f3004b-b954-4cf5-c08d-fae94d0f6c6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive/MIDCN'"
      ],
      "metadata": {
        "id": "y8TNdH-gXHo3",
        "outputId": "7bc066ec-c4c8-4923-d65b-74f8eed03d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MIDCN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run main.py"
      ],
      "metadata": {
        "id": "EfOAmgz4XPx1",
        "outputId": "2ee54ef4-aceb-4884-d0c2-3907868f1e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/MIDCN/process_smiles.py:38: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  GCNData = DATA.Data(x=torch.FloatTensor(features),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/MyDrive/MIDCN/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/MIDCN/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mout_HTN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_HTN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhetero_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrug_microbe_disease_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mout_MCHNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_MCHNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_drug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmic_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_HTN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_HTN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrug_microbe_disease_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrug_microbe_disease_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrug_microbe_disease_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/MIDCN/model_hetero.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dru_adj, mic_feature, dis_feature)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Process drug graph using GINConv layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdru_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdru_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdru_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mx_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mx_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mx_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gin_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx_r\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    }
  ]
}